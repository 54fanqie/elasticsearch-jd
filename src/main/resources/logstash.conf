input {
    jdbc {
        # 设置 MySql/MariaDB 数据库url以及数据库名称
        jdbc_connection_string => "jdbc:mysql://mysql.gmdev.baiwang-inner.com:3306/seal_manager_dev?useUnicode=true&allowMultiQuerie=true&characterEncoding=utf-8&serverTimezone=UTC"
        # 用户名和密码
        jdbc_user => "root"
        jdbc_password => "123456"
        # 数据库驱动所在位置，可以是绝对路径或者相对路径
        jdbc_driver_library => "/usr/local/logstash-7.12.0/my/mysql-connector-java-8.0.19.jar"
        # 驱动类名
        jdbc_driver_class => "com.mysql.cj.jdbc.Driver"
        # 开启分页
        jdbc_paging_enabled => true
        # 分页每页数量，可以自定义
        jdbc_page_size => "1000"
        # 设置时区
        jdbc_default_timezone =>"Asia/Shanghai"
        # 执行的sql文件路径
        statement_filepath => "/usr/local/logstash-7.12.0/my/my.sql"
        #直接写sql语句
        #statement =>

        # 设置定时任务间隔  含义：分、时、天、月、年，全部为*默认含义为每分钟跑一次任务,如：每10分钟更新一次 */6 * * * *
        schedule => "* * * * *"
        # 索引类型
        type => "_doc"
        #是否需要记录某个字段值,如果为true,我们可以自定义要记录的字段值，例如id或date字段。如果为false，记录的是上次执行的标记，默认是一个timestamp.
        use_column_value => true
	    #记录上次执行字段值路径。我们可以在sql语句中这么写：WHERE ID > :last_sql_value。其中 :sql_last_value 取得就是该文件中的值
        last_run_metadata_path => "/usr/local/logstash-7.12.0/my/last_id"
        #如果use_column_value为真,需配置此参数. 指定增量更新的字段名。当然该字段必须是递增的，比如id或date字段。
        tracking_column => "id"
        # tracking_column 对应字段的类型，只能选择timestamp或者numeric(数字类型)，默认numeric，所以可以不写这个配置
        tracking_column_type => "numeric"

        #如果为true，每次会记录所更新的字段的值,并保存到 last_run_metadata_path 指定的文件中
        record_last_run => true
        # 是否清除 last_run_metadata_path 的记录，true则每次都从头开始查询所有的数据库记录
        clean_run => false
        # 是否将字段名称转小写。默认是true。这里注意Elasticsearch是区分大小写的
        lowercase_column_names => false
    }
}
filter{
    # 把东八区时间赋值给新建的n_logstashStamp 字段,logstash不允许自建的特殊字段如带@标识的字段
    ruby{
       code => "event.set('n_logstashStamp', (event.get('@timestamp').time.localtime + 8*60*60).strftime('%Y-%m-%d %H:%M:%S'))"
    }
    date {
         match => [ "n_logstashStamp", "yyyy-MM-dd HH:mm:ss" ]
         target => @timestamp
    }

    mutate  {
         #将不需要的JSON字段过滤，且不会被存入 ES 中，@timestamp、@version 无用字段可删除
         remove_field => ["tags", "@timestamp", "@version"]
    }

}
output {
    elasticsearch {
        # es地址 集群数组hosts => ["10.100.4.10:9200","10.100.4.10:9201"]
        hosts => ["10.100.4.10:9200"]
        # 同步的索引名
        index => "ps_seal_log%{+yyyyMM}"
        # 设置_docID和数据相同
        document_id => "%{id}"
        #自定义模板名称
        template_name => "ps_seal_log"
        #模板地址位置
        template => "/usr/local/logstash-7.12.0/my/ps_seal_log_template.json"
        #重写模板
        template_overwrite => true
        #默认true, false 关闭logstash自动管理模板功能，如果有自定义模板，设置为false
        manage_template => false
    }
    # 日志输出
    stdout {
        codec => json_lines
    }
}







# 格式化 @timestamp
filter{

    grok {
        match => {
            "message" => "%{TIMESTAMP_ISO8601:localtime}"
        }
    }
    # 方式一:可切格式化时间并调整时区
    date {
        match => ["localtime", "yyyy-MM-dd'T'HH:mm:ssZZ"]
        target => "@timestamp"
    }
    # 方式二:只调整时区
    date {
         match => ["localtime", "ISO8601"]
         target => "@timestamp"
    }
}